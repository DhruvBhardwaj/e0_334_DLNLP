{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dbhar\\anaconda3\\envs\\e0_334_DLNLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_str = \"Train dataset.csv\"\n",
    "data_df = pd.read_csv(data_csv_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = {}\n",
    "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "  #print(line)\n",
    "  values = line.split()\n",
    "  try:\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    emb_model[word.lower()] = coefs    \n",
    "  except:\n",
    "    pass\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = list(emb_model.keys())\n",
    "def create_embedding_matrix(embedding_dict,dimension):  \n",
    "  embedding_matrix=np.zeros((len(emb_list)+1,dimension))\n",
    "  \n",
    "  for idx,item in enumerate(emb_list):\n",
    "    embedding_matrix[idx]=embedding_dict[item]\n",
    "  return embedding_matrix\n",
    "\n",
    "emb_matrix = create_embedding_matrix(emb_model,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer_matrix_glove_6B_300D.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([emb_list, emb_matrix], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_vec_tokenizer(seq):    \n",
    "    doc = nlp(re.sub('<[^<]+?>', '', seq))\n",
    "    ls = [t.text for t in doc if (t.is_alpha==True and t.is_punct==False and t.like_url==False)]\n",
    "    #print(ls)\n",
    "    #print(len(ls))\n",
    "    vec=[]\n",
    "    for word in ls:\n",
    "        print(word)        \n",
    "        try:\n",
    "            vec.append(emb_list.index(word.lower()))\n",
    "        except:\n",
    "            pass    \n",
    "    return vec\n",
    "\n",
    "def label_str_to_num(label):    \n",
    "    if(label.lower()=='positive'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', 'Oz', 'episode', 'you', 'be', 'hooked', 'They', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'The', 'first', 'thing', 'that', 'struck', 'me', 'about', 'Oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'GO', 'Trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'This', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'Its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'It', 'is', 'called', 'OZ', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'Oswald', 'Maximum', 'Security', 'State', 'Penitentary', 'It', 'focuses', 'mainly', 'on', 'Emerald', 'City', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'Em', 'City', 'is', 'home', 'to', 'many', 'Aryans', 'Muslims', 'gangstas', 'Latinos', 'Christians', 'Italians', 'Irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'I', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', 'dare', 'Forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'OZ', 'does', 'mess', 'around', 'The', 'first', 'episode', 'I', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'I', 'could', 'say', 'I', 'was', 'ready', 'for', 'it', 'but', 'as', 'I', 'watched', 'more', 'I', 'developed', 'a', 'taste', 'for', 'Oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'Not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'Watching', 'Oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n",
      "One\n",
      "of\n",
      "the\n",
      "other\n",
      "reviewers\n",
      "has\n",
      "mentioned\n",
      "that\n",
      "after\n",
      "watching\n",
      "just\n",
      "Oz\n",
      "episode\n",
      "you\n",
      "be\n",
      "hooked\n",
      "They\n",
      "are\n",
      "right\n",
      "as\n",
      "this\n",
      "is\n",
      "exactly\n",
      "what\n",
      "happened\n",
      "with\n",
      "me\n",
      "The\n",
      "first\n",
      "thing\n",
      "that\n",
      "struck\n",
      "me\n",
      "about\n",
      "Oz\n",
      "was\n",
      "its\n",
      "brutality\n",
      "and\n",
      "unflinching\n",
      "scenes\n",
      "of\n",
      "violence\n",
      "which\n",
      "set\n",
      "in\n",
      "right\n",
      "from\n",
      "the\n",
      "word\n",
      "GO\n",
      "Trust\n",
      "me\n",
      "this\n",
      "is\n",
      "not\n",
      "a\n",
      "show\n",
      "for\n",
      "the\n",
      "faint\n",
      "hearted\n",
      "or\n",
      "timid\n",
      "This\n",
      "show\n",
      "pulls\n",
      "no\n",
      "punches\n",
      "with\n",
      "regards\n",
      "to\n",
      "drugs\n",
      "sex\n",
      "or\n",
      "violence\n",
      "Its\n",
      "is\n",
      "hardcore\n",
      "in\n",
      "the\n",
      "classic\n",
      "use\n",
      "of\n",
      "the\n",
      "word\n",
      "It\n",
      "is\n",
      "called\n",
      "OZ\n",
      "as\n",
      "that\n",
      "is\n",
      "the\n",
      "nickname\n",
      "given\n",
      "to\n",
      "the\n",
      "Oswald\n",
      "Maximum\n",
      "Security\n",
      "State\n",
      "Penitentary\n",
      "It\n",
      "focuses\n",
      "mainly\n",
      "on\n",
      "Emerald\n",
      "City\n",
      "an\n",
      "experimental\n",
      "section\n",
      "of\n",
      "the\n",
      "prison\n",
      "where\n",
      "all\n",
      "the\n",
      "cells\n",
      "have\n",
      "glass\n",
      "fronts\n",
      "and\n",
      "face\n",
      "inwards\n",
      "so\n",
      "privacy\n",
      "is\n",
      "not\n",
      "high\n",
      "on\n",
      "the\n",
      "agenda\n",
      "Em\n",
      "City\n",
      "is\n",
      "home\n",
      "to\n",
      "many\n",
      "Aryans\n",
      "Muslims\n",
      "gangstas\n",
      "Latinos\n",
      "Christians\n",
      "Italians\n",
      "Irish\n",
      "and\n",
      "more\n",
      "so\n",
      "scuffles\n",
      "death\n",
      "stares\n",
      "dodgy\n",
      "dealings\n",
      "and\n",
      "shady\n",
      "agreements\n",
      "are\n",
      "never\n",
      "far\n",
      "away\n",
      "I\n",
      "would\n",
      "say\n",
      "the\n",
      "main\n",
      "appeal\n",
      "of\n",
      "the\n",
      "show\n",
      "is\n",
      "due\n",
      "to\n",
      "the\n",
      "fact\n",
      "that\n",
      "it\n",
      "goes\n",
      "where\n",
      "other\n",
      "shows\n",
      "would\n",
      "dare\n",
      "Forget\n",
      "pretty\n",
      "pictures\n",
      "painted\n",
      "for\n",
      "mainstream\n",
      "audiences\n",
      "forget\n",
      "charm\n",
      "forget\n",
      "romance\n",
      "OZ\n",
      "does\n",
      "mess\n",
      "around\n",
      "The\n",
      "first\n",
      "episode\n",
      "I\n",
      "ever\n",
      "saw\n",
      "struck\n",
      "me\n",
      "as\n",
      "so\n",
      "nasty\n",
      "it\n",
      "was\n",
      "surreal\n",
      "I\n",
      "could\n",
      "say\n",
      "I\n",
      "was\n",
      "ready\n",
      "for\n",
      "it\n",
      "but\n",
      "as\n",
      "I\n",
      "watched\n",
      "more\n",
      "I\n",
      "developed\n",
      "a\n",
      "taste\n",
      "for\n",
      "Oz\n",
      "and\n",
      "got\n",
      "accustomed\n",
      "to\n",
      "the\n",
      "high\n",
      "levels\n",
      "of\n",
      "graphic\n",
      "violence\n",
      "Not\n",
      "just\n",
      "violence\n",
      "but\n",
      "injustice\n",
      "crooked\n",
      "guards\n",
      "who\n",
      "be\n",
      "sold\n",
      "out\n",
      "for\n",
      "a\n",
      "nickel\n",
      "inmates\n",
      "who\n",
      "kill\n",
      "on\n",
      "order\n",
      "and\n",
      "get\n",
      "away\n",
      "with\n",
      "it\n",
      "well\n",
      "mannered\n",
      "middle\n",
      "class\n",
      "inmates\n",
      "being\n",
      "turned\n",
      "into\n",
      "prison\n",
      "bitches\n",
      "due\n",
      "to\n",
      "their\n",
      "lack\n",
      "of\n",
      "street\n",
      "skills\n",
      "or\n",
      "prison\n",
      "experience\n",
      "Watching\n",
      "Oz\n",
      "you\n",
      "may\n",
      "become\n",
      "comfortable\n",
      "with\n",
      "what\n",
      "is\n",
      "uncomfortable\n",
      "viewing\n",
      "thats\n",
      "if\n",
      "you\n",
      "can\n",
      "get\n",
      "in\n",
      "touch\n",
      "with\n",
      "your\n",
      "darker\n",
      "side\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16300/4188262492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(row['sentiment'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_to_vec_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_str_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "text=[]\n",
    "for index, row in data_df.iterrows():\n",
    "    #print(row['review'])\n",
    "    #print(row['sentiment'])    \n",
    "    aa = seq_to_vec_tokenizer(row['review'])\n",
    "    if(len(aa) > 0):\n",
    "        print(aa)\n",
    "        text.append(aa)\n",
    "        labels.append(label_str_to_num(row['sentiment']))\n",
    "        print(index,len(aa))\n",
    "    else:\n",
    "        print(index,'Zero size')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('e0_334_DLNLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faf770d1e47eede554824f13152ff79334d378d32be76b65a9d49549787be319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
